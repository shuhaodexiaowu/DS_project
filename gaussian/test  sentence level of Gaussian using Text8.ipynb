{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from word2gauss import embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "word2gauss.embeddings.GaussianEmbedding"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.GaussianEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from word2gauss import GaussianEmbedding, iter_pairs\n",
    "from vocab import Vocabulary\n",
    "\n",
    "# v = Vocabulary()\n",
    "# with open('./text8.txt','r', encoding='utf-8') as corpus:\n",
    "#     v.create(corpus,[(10000000,5,350)])\n",
    "#\n",
    "# v.save('text8_voc.gz')  #save file\n",
    "\n",
    "# load vocab\n",
    "v = Vocabulary.load('F:/project_code/text8_voc.gz')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embed =GaussianEmbedding(len(v),50,covariance_type='spherical', energy_type='KL')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('F:/project_code/text8.txt','r', encoding='utf-8') as corpus:\n",
    "    embed.train(iter_pairs(corpus,v),n_workers =8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicA = []\n",
    "dicB = []\n",
    "val = []\n",
    "with open(\"F:/MSc DS/Project/compositional datasets/KS2016-VO.txt\") as f:\n",
    "    for line in f:\n",
    "        linelist = line.split(\",\")\n",
    "        dicA.append(linelist[0])\n",
    "        dicB.append(linelist[1])\n",
    "        val.append(linelist[2])\n",
    "        \n",
    "        \n",
    "# convert the T to 1 F to 0 in val list\n",
    "n = len(val)\n",
    "for i in range(n):\n",
    "    if val[i]=='T\\n':\n",
    "        val[i]=1\n",
    "    else:\n",
    "        val[i]=0\n",
    "# dicA  list to store the first phrase\n",
    "# dicB  list to store the second pharse\n",
    "# val  true val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dicA.pop(338)\n",
    "dicB.pop(338)\n",
    "val.pop(338)\n",
    "dicA.pop(338)\n",
    "dicB.pop(338)\n",
    "val.pop(338)\n",
    "dicA.pop(370)\n",
    "dicB.pop(370)\n",
    "val.pop(370)\n",
    "dicA.pop(370)\n",
    "dicB.pop(370)\n",
    "val.pop(370)\n",
    "dicA.pop(404)\n",
    "dicB.pop(404)\n",
    "val.pop(404)\n",
    "dicA.pop(404)\n",
    "dicB.pop(404)\n",
    "val.pop(404)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def KL_div(mui,muj, sigmai,sigmaj,K =50):\n",
    "#     sigma_ratio = sigmai/sigmaj\n",
    "#     det_fac = K*np.log(sigma_ratio)\n",
    "#     trace_fac = K* sigma_ratio\n",
    "    \n",
    "#     mu_diff_sq = 0\n",
    "#     for k in range(K):\n",
    "#         mu_diff = mui[k]-muj[k]\n",
    "#         mu_diff_sq += mu_diff* mu_diff\n",
    "        \n",
    "#     return 0.5*(trace_fac + mu_diff_sq/sigmaj - K - det_fac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compute_KL(listA,listB,Gauss):\n",
    "#     '''\n",
    "#     imput two phrase or sentences lists\n",
    "#     tokenize each pair and get a new gaussain by merging these distributions\n",
    "#     compute KL pred for each pair\n",
    "\n",
    "#     '''\n",
    "\n",
    "#     n = len(listA)\n",
    "#     KL_list = []\n",
    "#     for i in range(n):\n",
    "#         phraseA = listA[i].split()\n",
    "#         phraseB = listB[i].split()\n",
    "#         muA = 0.5*(Gauss.mu[v.word2id(phraseA[0].lower())] + Gauss.mu[v.word2id(phraseA[1].lower())])\n",
    "#         muB = 0.5*(Gauss.mu[v.word2id(phraseB[0].lower())] + Gauss.mu[v.word2id(phraseB[1].lower())])\n",
    "#         sigmaA = 0.5*(Gauss.sigma[v.word2id(phraseA[0].lower())] + Gauss.sigma[v.word2id(phraseA[1].lower())])\n",
    "#         sigmaB = 0.5*(Gauss.sigma[v.word2id(phraseB[0].lower())] + Gauss.sigma[v.word2id(phraseB[1].lower())])\n",
    "#         kl =KL_div(muA,muB,sigmaA,sigmaB)\n",
    "#         KL_list.append(kl)\n",
    "\n",
    "#     return KL_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5040562466197944\n"
     ]
    }
   ],
   "source": [
    "# pred = compute_KL(dicA, dicB,embed)\n",
    "# from sklearn.metrics import roc_auc_score\n",
    "# result = roc_auc_score(val, pred)\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed2 =GaussianEmbedding(len(v),50,covariance_type='diagonal', energy_type='KL')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('F:/project_code/text8.txt','r', encoding='utf-8') as corpus:\n",
    "    embed2.train(iter_pairs(corpus,v),n_workers =8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KL_div_dia(mui,muj, sigmai,sigmaj,K =50):\n",
    "    trace_fac =0.0\n",
    "    mu_diff_sq =0.0\n",
    "    det_fac =1.0\n",
    "    for k in range(K):\n",
    "        sigma_ratio = sigmai[k]/sigmaj[k]\n",
    "        trace_fac +=sigma_ratio\n",
    "        mu_diff = mui[k]-muj[k]\n",
    "        mu_diff_sq += mu_diff* mu_diff/sigmaj[k]\n",
    "        \n",
    "        det_fac *= sigma_ratio\n",
    "        \n",
    "        # boound def_fac\n",
    "    if det_fac < 1.0e-8:\n",
    "        det_fac = 1.0e-8\n",
    "    elif det_fac > 1.0e8:\n",
    "        det_fac = 1.0e8\n",
    "        \n",
    "    \n",
    "#     sigma_ratio = sigmai/sigmaj\n",
    "#     det_fac = K*np.log(sigma_ratio)\n",
    "#     trace_fac = K* sigma_ratio\n",
    "    \n",
    "#     mu_diff_sq = 0\n",
    "#     for k in range(K):\n",
    "#         mu_diff = mui[k]-muj[k]\n",
    "#         mu_diff_sq += mu_diff* mu_diff\n",
    "        \n",
    "    return 0.5*(trace_fac + mu_diff_sq - K - np.log(det_fac))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_KL_dia(listA,listB,Gauss):\n",
    "    '''\n",
    "    imput two phrase or sentences lists\n",
    "    tokenize each pair and get a new gaussain by merging these distributions\n",
    "    compute KL pred for each pair\n",
    "\n",
    "    '''\n",
    "\n",
    "    n = len(listA)\n",
    "    R_list = []\n",
    "    for i in range(n):\n",
    "        phraseA = listA[i].split()\n",
    "        phraseB = listB[i].split()\n",
    "        muA = 0.5*(Gauss.mu[v.word2id(phraseA[0].lower())] + Gauss.mu[v.word2id(phraseA[1].lower())])\n",
    "        muB = 0.5*(Gauss.mu[v.word2id(phraseB[0].lower())] + Gauss.mu[v.word2id(phraseB[1].lower())])\n",
    "        sigmaA = 0.25*(Gauss.sigma[v.word2id(phraseA[0].lower())] + Gauss.sigma[v.word2id(phraseA[1].lower())])\n",
    "        sigmaB = 0.25*(Gauss.sigma[v.word2id(phraseB[0].lower())] + Gauss.sigma[v.word2id(phraseB[1].lower())])\n",
    "        kl =KL_div_dia(muA,muB,sigmaA,sigmaB)\n",
    "        R_list.append(1/(1+kl))\n",
    "\n",
    "    return R_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4912925905895078\n"
     ]
    }
   ],
   "source": [
    "pred2 = compute_KL_dia(dicA, dicB,embed2)\n",
    "from sklearn.metrics import roc_auc_score\n",
    "result = roc_auc_score(val, pred2)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get sv dataset\n",
    "# get sv dataset\n",
    "dicA = []\n",
    "dicB = []\n",
    "val = []\n",
    "with open(\"F:/MSc DS/Project/compositional datasets/KS2016-SV.txt\") as f:\n",
    "    for line in f:\n",
    "        linelist = line.split(\",\")\n",
    "        dicA.append(linelist[0])\n",
    "        dicB.append(linelist[1])\n",
    "        val.append(linelist[2])\n",
    "\n",
    "# convert the T to 1 F to 0 in val list\n",
    "n = len(val)\n",
    "for i in range(n):\n",
    "    if val[i]=='T\\n':\n",
    "        val[i]=1\n",
    "    else:\n",
    "        val[i]=0\n",
    "# dicA  list to store "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "34\n",
      "92\n",
      "94\n",
      "104\n",
      "140\n",
      "196\n",
      "240\n",
      "250\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(dicA)):\n",
    "    for j in dicA[i].split():\n",
    "        try:\n",
    "            t =embed2.mu[v.word2id(j)]\n",
    "        except KeyError as e:\n",
    "            print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dicA.pop(20)\n",
    "dicB.pop(20)\n",
    "val.pop(20)\n",
    "dicA.pop(20)\n",
    "dicB.pop(20)\n",
    "val.pop(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dicA.pop(32)\n",
    "dicB.pop(32)\n",
    "val.pop(32)\n",
    "dicA.pop(32)\n",
    "dicB.pop(32)\n",
    "val.pop(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dicA.pop(96)\n",
    "dicB.pop(96)\n",
    "val.pop(96)\n",
    "dicA.pop(96)\n",
    "dicB.pop(96)\n",
    "val.pop(96)\n",
    "dicA.pop(130)\n",
    "dicB.pop(130)\n",
    "val.pop(130)\n",
    "dicA.pop(130)\n",
    "dicB.pop(130)\n",
    "val.pop(130)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dicA.pop(88)\n",
    "dicB.pop(88)\n",
    "val.pop(88)\n",
    "dicA.pop(88)\n",
    "dicB.pop(88)\n",
    "val.pop(88)\n",
    "dicA.pop(88)\n",
    "dicB.pop(88)\n",
    "val.pop(88)\n",
    "dicA.pop(88)\n",
    "dicB.pop(88)\n",
    "val.pop(88)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dicA.pop(184)\n",
    "dicB.pop(184)\n",
    "val.pop(184)\n",
    "dicA.pop(184)\n",
    "dicB.pop(184)\n",
    "val.pop(184)\n",
    "dicA.pop(226)\n",
    "dicB.pop(226)\n",
    "val.pop(226)\n",
    "dicA.pop(226)\n",
    "dicB.pop(226)\n",
    "val.pop(226)\n",
    "dicA.pop(234)\n",
    "dicB.pop(234)\n",
    "val.pop(234)\n",
    "dicA.pop(234)\n",
    "dicB.pop(234)\n",
    "val.pop(234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49162257495590833\n"
     ]
    }
   ],
   "source": [
    "pred3 = compute_KL_dia(dicA, dicB,embed2)\n",
    "from sklearn.metrics import roc_auc_score\n",
    "result = roc_auc_score(val, pred3)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get sv dataset\n",
    "dicA = []\n",
    "dicB = []\n",
    "val = []\n",
    "with open(\"F:/MSc DS/Project/compositional datasets/KS2016-SVO.txt\") as f:\n",
    "    for line in f:\n",
    "        linelist = line.split(\",\")\n",
    "        dicA.append(linelist[0])\n",
    "        dicB.append(linelist[1])\n",
    "        val.append(linelist[2])\n",
    "\n",
    "\n",
    "# convert the T to 1 F to 0 in val list\n",
    "n = len(val)\n",
    "for i in range(n):\n",
    "    if val[i]=='T\\n':\n",
    "        val[i]=1\n",
    "    else:\n",
    "        val[i]=0\n",
    "# dicA  list to store the first phrase\n",
    "# dicB  list to store the second pharse\n",
    "# val  true val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n",
      "38\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(dicA)):\n",
    "    for j in dicA[i].split():\n",
    "        try:\n",
    "            t =embed2.mu[v.word2id(j)]\n",
    "        except KeyError as e:\n",
    "            print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dicA.pop(26)\n",
    "dicB.pop(26)\n",
    "val.pop(26)\n",
    "dicA.pop(26)\n",
    "dicB.pop(26)\n",
    "val.pop(26)\n",
    "dicA.pop(36)\n",
    "dicB.pop(36)\n",
    "val.pop(36)\n",
    "dicA.pop(36)\n",
    "dicB.pop(36)\n",
    "val.pop(36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_KL_dia3(listA,listB,Gauss):\n",
    "    '''\n",
    "    imput two phrase or sentences lists\n",
    "    tokenize each pair and get a new gaussain by merging these distributions\n",
    "    compute KL pred for each pair\n",
    "\n",
    "    '''\n",
    "\n",
    "    n = len(listA)\n",
    "    R_list = []\n",
    "    for i in range(n):\n",
    "        phraseA = listA[i].split()\n",
    "        phraseB = listB[i].split()\n",
    "        muA_ = 0.5*(Gauss.mu[v.word2id(phraseA[0].lower())] + Gauss.mu[v.word2id(phraseA[1].lower())])\n",
    "        muB_ = 0.5*(Gauss.mu[v.word2id(phraseB[0].lower())] + Gauss.mu[v.word2id(phraseB[1].lower())])\n",
    "        sigmaA_ = 0.25*(Gauss.sigma[v.word2id(phraseA[0].lower())] + Gauss.sigma[v.word2id(phraseA[1].lower())])\n",
    "        sigmaB_ = 0.25*(Gauss.sigma[v.word2id(phraseB[0].lower())] + Gauss.sigma[v.word2id(phraseB[1].lower())])\n",
    "        muA =0.5*( muA_ + Gauss.mu[v.word2id(phraseA[2].lower())])\n",
    "        muB = 0.5*( muB_ + Gauss.mu[v.word2id(phraseB[2].lower())])\n",
    "        sigmaA = 0.25*(sigmaA_ + Gauss.sigma[v.word2id(phraseA[2].lower())])\n",
    "        sigmaB = 0.25*(sigmaB_ + Gauss.sigma[v.word2id(phraseB[2].lower())])\n",
    "        kl =KL_div_dia(muA,muB,sigmaA,sigmaB)\n",
    "        R_list.append(1/(1+kl))\n",
    "\n",
    "    return R_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49091695501730104\n"
     ]
    }
   ],
   "source": [
    "pred4 = compute_KL_dia3(dicA, dicB,embed2)\n",
    "from sklearn.metrics import roc_auc_score\n",
    "result = roc_auc_score(val, pred4)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
